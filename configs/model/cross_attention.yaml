instance:
  _target_: models.cross_attention.DinoV2BertWithCrossAttention
  image_hidden_dims: [1024, 512, 256]
  text_hidden_dims: [1024, 512, 256]
  fusion_dim: 512
  output_hidden_dims: [1024, 512, 256]
  dropout_rate: 0.2
  freeze_bert: True
  freeze_dinov2: True
  num_attention_heads: 8
  bert_model: "bert-base-uncased"
  text_max_length: 128

name: DINOV2_BERT_CROSS_ATTENTION